import streamlit as st
import pandas as pd
import os
from openai import OpenAI 

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìœ¤ì„± ì‹¤ë¬´ AI (GitHub ì™„ì„±í˜•)", page_icon="ğŸ›¡ï¸", layout="wide")

# 2. GitHub Models ì„¤ì •
github_token = st.secrets.get("GITHUB_TOKEN")

if github_token:
    client = OpenAI(
        base_url="https://models.inference.ai.azure.com",
        api_key=github_token,
    )
else:
    st.error("ğŸ”‘ Secretsì— GITHUB_TOKENì„ ë“±ë¡í•´ì£¼ì„¸ìš”!")
    st.stop()

# 3. ì‚¬ì´ë“œë°” ë° ì—…ë¬´ ì„ íƒ
st.sidebar.title("ğŸ“‚ ì—…ë¬´ ì œì–´íŒ")
main_menu = st.sidebar.radio("ì—…ë¬´ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ["WPS (ìš©ì ‘ ê·œê²©)", "TER (íŠ¸ëŸ¬ë¸” ë¦¬í¬íŠ¸)"])

# 4. íŒŒì¼ ë¡œë“œ ë¡œì§ (ì˜¤ë¹  ê¸°ì¡´ ê²½ë¡œ ì™„ë²½ ë°˜ì˜ ğŸ¤™)
if main_menu == "WPS (ìš©ì ‘ ê·œê²©)":
    st.title("ğŸ‘¨â€ğŸ­ WPS ì‹¤ë¬´ ì§€ì‹ ë² ì´ìŠ¤")
    candidates = ["wps_list.XLSX", "wps_list.xlsx", "wps_list.xlsx.xlsx"]
    target_sheet = 0
else:
    st.title("ğŸ› ï¸ TER íŠ¸ëŸ¬ë¸” ì •ë°€ ë¶„ì„ ì‹œìŠ¤í…œ")
    candidates = ["ter_list.xlsx.xlsx", "ter_list.xlsx", "ter_list.XLSX"]
    target_sheet = 'TER'

file_path = next((f for f in candidates if os.path.exists(f)), None)

if file_path:
    try:
        xl = pd.ExcelFile(file_path, engine='openpyxl')
        df = pd.read_excel(xl, sheet_name=target_sheet if (isinstance(target_sheet, int) or target_sheet in xl.sheet_names) else 0)
        st.success(f"âœ… {file_path} ë¡œë“œ ì„±ê³µ! (ì´ {len(df):,}í–‰)")

        # 5. ì§ˆë¬¸ ë° ë‹µë³€ ì¸í„°í˜ì´ìŠ¤
        user_input = st.text_input(f"ğŸ’¬ {main_menu} ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”.")

        if user_input:
            with st.status("ğŸš€ GitHub Llama-3.1-70B ì—”ì§„ ë¶„ì„ ì¤‘...", expanded=True):
                # GitHub ëª¨ë¸ì€ 128k í† í°ì„ ì§€ì›í•˜ë¯€ë¡œ ë„‰ë„‰í•˜ê²Œ 1,000ì¤„ì„ ë³´ëƒ…ë‹ˆë‹¤! ğŸ¤™
                # 4.6MB ë°ì´í„° ì¤‘ ê°€ì¥ ìµœì‹  ë°ì´í„° ìœ„ì£¼ë¡œ ë¶„ì„í•´ìš”.
                context_data = df.tail(1000).to_csv(index=False)
                
                try:
                    response = client.chat.completions.create(
                        messages=[
                            {"role": "system", "content": "ë„ˆëŠ” ìœ¤ì„±ì˜ 2ì°¨ì „ì§€ ì¥ë¹„ ì „ë¬¸ê°€ì•¼. ì œê³µëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µí•´ì¤˜."},
                            {"role": "user", "content": f"[ë°ì´í„°]\n{context_data}\n\n[ì§ˆë¬¸]\n{user_input}"}
                        ],
                        model="meta-llama-3.1-70b-instruct", # ì´ë¦„ ë’¤ì— -instructë¥¼ ê¼­ ë¶™ì—¬ì•¼ í•´ìš”!
                        temperature=0.2,
                    )
                    st.info(response.choices[0].message.content)
                except Exception as e:
                    st.error(f"ğŸš¨ ëª¨ë¸ í˜¸ì¶œ ì—ëŸ¬: {e}")
        
        with st.expander("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(df.head(100))
            
    except Exception as e:
        st.error(f"ğŸš¨ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
else:
    st.error("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì„ í™•ì¸í•´ ì£¼ì„¸ìš”!")
