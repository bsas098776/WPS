import streamlit as st
import pandas as pd
import os
from groq import Groq

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìœ¤ì„± ì‹¤ë¬´ AI (ë°ì´í„° ì••ì¶• ìµœì í™”)", page_icon="ğŸ›¡ï¸", layout="wide")

# 2. Groq API ì„¤ì •
api_key = st.secrets.get("GROQ_API_KEY")
client = Groq(api_key=api_key) if api_key else None

def ask_ai(prompt, model_id):
    try:
        completion = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ìœ¤ì„±ì˜ ì „ë¬¸ê°€ì•¼. ì œê³µëœ ë°ì´í„°ë¥¼ ê¼¼ê¼¼íˆ ë¶„ì„í•´ì„œ ë‹µí•´ì¤˜."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"ğŸš¨ ì—ëŸ¬: {e}"

# 3. ì‚¬ì´ë“œë°” ì œì–´íŒ
st.sidebar.title("ğŸ“‚ ì œì–´íŒ")
selected_model = "llama-3.3-70b-versatile" # ê°€ì¥ ë˜‘ë˜‘í•œ ëª¨ë¸ ê³ ì • ğŸ¤™

# 4. íŒŒì¼ ë¡œë“œ ë° ìµœì í™” ë¶„ì„
candidates = ["ter_list.xlsx.xlsx", "ter_list.xlsx", "wps_list.XLSX"]
file_path = next((f for f in candidates if os.path.exists(f)), None)

if file_path and client:
    xl = pd.ExcelFile(file_path, engine='openpyxl')
    df = pd.read_excel(xl, sheet_name='TER' if 'TER' in xl.sheet_names else 0)
    st.success(f"âœ… {file_path} ë¡œë“œ ì™„ë£Œ!")

    user_input = st.text_input("ğŸ’¬ ë¶„ì„ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì´ë…¸ë¯¹ì„œ ê´€ë ¨ ëª¨ë“  ì´ìŠˆ ìš”ì•½í•´ì¤˜)")

    if user_input:
        with st.status("ğŸš€ í•µì‹¬ ë°ì´í„° ì¶”ì¶œ ë° ì •ë°€ ë¶„ì„ ì¤‘..."):
            # [ì••ì¶• ì „ëµ] ë¶ˆí•„ìš”í•œ ì—´ì€ ë¹¼ê³  í•µì‹¬ ì—´ë§Œ ì¶”ì¶œí•´ì„œ í† í°ì„ ì•„ë‚ë‹ˆë‹¤! ğŸ¤™
            # ë§¤ë‹ˆì €ë‹˜ì˜ íŒŒì¼ ì»¬ëŸ¼ëª…ì— ë§ì¶° 'í˜„ìƒ', 'ì¡°ì¹˜' ë“± ì£¼ìš” ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì„¸ìš”.
            # ì˜ˆ: available_cols = ['ë¶€ìœ„', 'í˜„ìƒ', 'ì›ì¸', 'ì¡°ì¹˜']
            # ì—¬ê¸°ì„œëŠ” ìš°ì„  ì „ì²´ ì¤‘ í…ìŠ¤íŠ¸ê°€ ë§ì€ ìƒìœ„ ì»¬ëŸ¼ ìœ„ì£¼ë¡œ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
            
            refined_df = df.iloc[:, [1, 2, 3, 4, 5]] # ì£¼ìš” ì»¬ëŸ¼ 5ê°œë§Œ ì„ íƒ (ì˜ˆì‹œ)
            
            # í† í° í•œë„ ë‚´ì—ì„œ ìµœëŒ€í•œ ë§ì€ í–‰(ì•½ 600~800í–‰)ì„ ë³´ëƒ…ë‹ˆë‹¤.
            context_data = refined_df.tail(700).to_csv(index=False)
            
            prompt = f"ì•„ë˜ ë°ì´í„°ëŠ” ìµœê·¼ ë°œìƒí•œ íŠ¸ëŸ¬ë¸” ë¦¬í¬íŠ¸ì•¼. ì§ˆë¬¸ì— ë‹µí•´ì¤˜.\n\n[ë°ì´í„°]\n{context_data}\n\n[ì§ˆë¬¸]\n{user_input}"
            
            answer = ask_ai(prompt, selected_model)
            st.info(answer)
