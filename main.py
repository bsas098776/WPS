import streamlit as st
import pandas as pd
import google.generativeai as genai
import os

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìœ¤ì„± ì‹¤ë¬´ AI ì „ë¬¸ê°€ (ì•ˆì •í™” ë²„ì „)", page_icon="ğŸ›¡ï¸", layout="wide")

# 2. Gemini API ì„¤ì •
api_key = st.secrets.get("GEMINI_API_KEY")

if api_key:
    genai.configure(api_key=api_key)
    
    # [í•µì‹¬ ìˆ˜ì •] 404 ì—ëŸ¬ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ê°€ë™ ê°€ëŠ¥í•œ ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ íƒìƒ‰í•©ë‹ˆë‹¤! ğŸ¤™
    available_models = ['gemini-1.5-flash', 'gemini-1.0-pro', 'gemini-pro']
    model = None
    
    for model_name in available_models:
        try:
            model = genai.GenerativeModel(model_name)
            # í…ŒìŠ¤íŠ¸ í˜¸ì¶œë¡œ ëª¨ë¸ì´ ì •ë§ ìˆëŠ”ì§€ í™•ì¸
            test_res = model.generate_content("test", generation_config={"max_output_tokens": 1})
            st.sidebar.success(f"ğŸ“¡ ì—°ê²° ì„±ê³µ: {model_name}")
            break
        except:
            continue
            
    if model is None:
        st.error("ğŸš¨ ì‚¬ìš© ê°€ëŠ¥í•œ ì œë¯¸ë‹ˆ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ ê¶Œí•œì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        st.stop()
else:
    st.error("ğŸ”‘ Secretsì— GEMINI_API_KEYë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”!")
    st.stop()

# 3. ì‚¬ì´ë“œë°” ì—…ë¬´ ì„ íƒ
st.sidebar.title("ğŸ“‚ ì—…ë¬´ ì œì–´íŒ")
main_menu = st.sidebar.radio("ì—…ë¬´ ëª¨ë“œ", ["WPS (ìš©ì ‘ ê·œê²©)", "TER (íŠ¸ëŸ¬ë¸” ë¦¬í¬íŠ¸)"])

# 4. íŒŒì¼ ë¡œë“œ
if main_menu == "WPS (ìš©ì ‘ ê·œê²©)":
    st.title("ğŸ‘¨â€ğŸ­ WPS ì‹¤ë¬´ ì§€ì‹ ë² ì´ìŠ¤")
    candidates = ["wps_list.XLSX", "wps_list.xlsx"]
    target_sheet = 0
else:
    st.title("ğŸ› ï¸ TER íŠ¸ëŸ¬ë¸” ì •ë°€ ë¶„ì„ ì‹œìŠ¤í…œ")
    candidates = ["ter_list.xlsx.xlsx", "ter_list.xlsx", "ter_list.XLSX"]
    target_sheet = 'TER'

file_path = next((f for f in candidates if os.path.exists(f)), None)

try:
    if file_path:
        xl = pd.ExcelFile(file_path, engine='openpyxl')
        df = pd.read_excel(xl, sheet_name=target_sheet if (isinstance(target_sheet, int) or target_sheet in xl.sheet_names) else 0)
        st.success(f"âœ… {file_path} ë¡œë“œ ì™„ë£Œ! (ì´ {len(df):,}í–‰)")

        # 5. ì§ˆë¬¸ ë° ë‹µë³€
        user_input = st.text_input(f"ğŸ’¬ {main_menu}ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”.")

        if user_input:
            with st.status("ğŸš€ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...", expanded=True):
                # [ì•ˆì „ ì¥ì¹˜] 1.0 Pro ëª¨ë¸ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë°ì´í„°ë¥¼ 200ì¤„ë¡œ ì ì ˆíˆ ì¡°ì ˆí•©ë‹ˆë‹¤. ğŸ¤™
                # 4.6MB ì „ì²´ê°€ ì•ˆ ë˜ë©´ ì—¬ê¸°ì„œë¶€í„° ì¡°ê¸ˆì”© ì¤„ì—¬ê°€ë©° ìµœì ì ì„ ì°¾ì„ ê±°ì˜ˆìš”!
                refined_df = df.tail(200) 
                context_data = refined_df.to_csv(index=False)
                
                prompt = f"ë„ˆëŠ” ìœ¤ì„±ì˜ ì „ë¬¸ê°€ì•¼. ì•„ë˜ ë°ì´í„°ë¥¼ ë³´ê³  ì˜¤ë¹ ì˜ ì§ˆë¬¸ì— ë‹µí•´ì¤˜.\n\n[ë°ì´í„°]\n{context_data}\n\n[ì§ˆë¬¸]\n{user_input}"
                
                try:
                    response = model.generate_content(prompt)
                    st.info(response.text)
                except Exception as e:
                    st.error(f"ğŸš¨ ë¶„ì„ ì—ëŸ¬: {e}")
        
        with st.expander("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(df.head(100))
    else:
        st.error("âŒ ë¶„ì„í•  ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
except Exception as e:
    st.error(f"ğŸš¨ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
