import streamlit as st
import pandas as pd
import os
from openai import OpenAI 

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìœ¤ì„± ì‹¤ë¬´ AI (GitHub ëª¨ë¸ ì•ˆì •í™”)", page_icon="ğŸ›¡ï¸", layout="wide")

# 2. GitHub Models ì„¤ì •
github_token = st.secrets.get("GITHUB_TOKEN")

if github_token:
    client = OpenAI(
        base_url="https://models.inference.ai.azure.com",
        api_key=github_token,
    )
else:
    st.error("ğŸ”‘ Secretsì— GITHUB_TOKENì„ ë“±ë¡í•´ì£¼ì„¸ìš”!")
    st.stop()

# 3. ì‚¬ì´ë“œë°” ì—…ë¬´ ì„ íƒ
st.sidebar.title("ğŸ“‚ ì—…ë¬´ ì œì–´íŒ")
main_menu = st.sidebar.radio("ì—…ë¬´ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ["WPS (ìš©ì ‘ ê·œê²©)", "TER (íŠ¸ëŸ¬ë¸” ë¦¬í¬íŠ¸)"])

# 4. íŒŒì¼ ë¡œë“œ (ì˜¤ë¹  ê¸°ì¡´ ê²½ë¡œ ì™„ë²½ ìœ ì§€ ğŸ¤™)
if main_menu == "WPS (ìš©ì ‘ ê·œê²©)":
    st.title("ğŸ‘¨â€ğŸ­ WPS ì‹¤ë¬´ ì§€ì‹ ë² ì´ìŠ¤")
    candidates = ["wps_list.XLSX", "wps_list.xlsx", "wps_list.xlsx.xlsx"]
    target_sheet = 0
else:
    st.title("ğŸ› ï¸ TER íŠ¸ëŸ¬ë¸” ì •ë°€ ë¶„ì„ ì‹œìŠ¤í…œ")
    candidates = ["ter_list.xlsx.xlsx", "ter_list.xlsx", "ter_list.XLSX"]
    target_sheet = 'TER'

file_path = next((f for f in candidates if os.path.exists(f)), None)

if file_path:
    try:
        xl = pd.ExcelFile(file_path, engine='openpyxl')
        df = pd.read_excel(xl, sheet_name=target_sheet if (isinstance(target_sheet, int) or target_sheet in xl.sheet_names) else 0)
        st.success(f"âœ… {file_path} ë¡œë“œ ì™„ë£Œ! (ì´ {len(df):,}í–‰)")

        # 5. ì§ˆë¬¸ ë° ë‹µë³€ ì¸í„°í˜ì´ìŠ¤
        user_input = st.text_input(f"ğŸ’¬ {main_menu} ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”.")

        if user_input:
            with st.status("ğŸš€ GitHub AI ì—”ì§„ ë¶„ì„ ì¤‘...", expanded=True):
                # ë°ì´í„° 1,000ì¤„ ì „ì†¡ ğŸ¤™
                context_data = df.tail(1000).to_csv(index=False)
                
                # [í•´ê²° í¬ì¸íŠ¸] ëª¨ë¸ ì´ë¦„ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤!
                model_candidates = ["Meta-Llama-3.1-70B-Instruct", "gpt-4o", "Llama-3.3-70B-Instruct"]
                success = False
                
                for target_model in model_candidates:
                    try:
                        response = client.chat.completions.create(
                            messages=[
                                {"role": "system", "content": "ë„ˆëŠ” ìœ¤ì„±ì˜ 2ì°¨ì „ì§€ ì¥ë¹„ ì „ë¬¸ê°€ì•¼. ì œê³µëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µí•´ì¤˜."},
                                {"role": "user", "content": f"[ë°ì´í„°]\n{context_data}\n\n[ì§ˆë¬¸]\n{user_input}"}
                            ],
                            model=target_model,
                            temperature=0.2,
                        )
                        st.info(f"âœ¨ ë¶„ì„ ëª¨ë¸: {target_model}")
                        st.write(response.choices[0].message.content)
                        success = True
                        break # ì„±ê³µí•˜ë©´ ë£¨í”„ íƒˆì¶œ!
                    except Exception as e:
                        if "unknown_model" in str(e).lower():
                            continue # ë‹¤ìŒ ëª¨ë¸ë¡œ ì‹œë„
                        else:
                            st.error(f"ğŸš¨ ì˜¤ë¥˜ ë°œìƒ ({target_model}): {e}")
                            break
                
                if not success:
                    st.error("ğŸš¨ GitHubì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”. í† í° ê¶Œí•œì´ë‚˜ ëª¨ë¸ëª…ì„ ë‹¤ì‹œ í™•ì¸í•´ì•¼ í•´ìš”.")
        
        with st.expander("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.dataframe(df.head(100))
            
    except Exception as e:
        st.error(f"ğŸš¨ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
else:
    st.error("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì„ í™•ì¸í•´ ì£¼ì„¸ìš”!")
