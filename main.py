import streamlit as st
import pandas as pd
import os
from groq import Groq

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìœ¤ì„± ì‹¤ë¬´ AI ì „ë¬¸ê°€ (ëª¨ë¸ ì„ íƒí˜•)", page_icon="ğŸ›¡ï¸", layout="wide")

# 2. Groq API ì„¤ì •
api_key = st.secrets.get("GROQ_API_KEY")
if api_key:
    client = Groq(api_key=api_key)
else:
    st.error("ğŸ”‘ Secretsì— GROQ_API_KEYë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”!")
    st.stop()

# 3. ì‚¬ì´ë“œë°”: ì—…ë¬´ ì„ íƒ ë° ëª¨ë¸ êµì²´ ê¸°ëŠ¥ ğŸ¤™
st.sidebar.title("ğŸ“‚ ì œì–´íŒ")
main_menu = st.sidebar.radio("ì—…ë¬´ ëª¨ë“œ", ["WPS (ìš©ì ‘ ê·œê²©)", "TER (íŠ¸ëŸ¬ë¸” ë¦¬í¬íŠ¸)"])

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ¤– ëª¨ë¸ ì—”ì§„ êµì²´")
selected_model = st.sidebar.selectbox(
    "ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
    ["llama-3.3-70b-versatile", "llama-3.1-8b-instant", "mixtral-8x7b-32768"],
    help="70bëŠ” ë˜‘ë˜‘í•˜ê³ , 8bëŠ” ë§¤ìš° ë¹ ë¦…ë‹ˆë‹¤!"
)

# 4. íŒŒì¼ ë¡œë“œ ë¡œì§ (ë§¤ë‹ˆì €ë‹˜ ê¸°ì¡´ ì„¤ì • ìœ ì§€)
candidates = ["ter_list.xlsx.xlsx", "ter_list.xlsx", "ter_list.XLSX", "wps_list.XLSX", "wps_list.xlsx"]
file_path = next((f for f in candidates if os.path.exists(f)), None)

def ask_ai(prompt, model_name):
    """ì„ íƒëœ Groq ëª¨ë¸ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        completion = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ìœ¤ì„±ì˜ ì „ë¬¸ê°€ì•¼. ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì¤˜."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        return completion.choices[0].message.content
    except Exception as e:
        if "rate_limit" in str(e).lower():
            return "ğŸš¨ ë„ˆë¬´ ë¹ ë¥´ê²Œ ì§ˆë¬¸í•˜ì…¨ì–´ìš”! ì ì‹œë§Œ ì‰¬ì—ˆë‹¤ê°€ ë‹¤ì‹œ í•´ì£¼ì„¸ìš”."
        return f"ğŸš¨ ëª¨ë¸ ì—ëŸ¬: {e}"

try:
    if file_path:
        xl = pd.ExcelFile(file_path, engine='openpyxl')
        df = pd.read_excel(xl, sheet_name='TER' if main_menu == "TER (íŠ¸ëŸ¬ë¸” ë¦¬í¬íŠ¸)" and 'TER' in xl.sheet_names else 0)
        st.success(f"âœ… {file_path} ë¡œë“œ ì™„ë£Œ! (í˜„ì¬ ì—”ì§„: {selected_model})")

        # 5. ì§ˆë¬¸ ë° ë¶„ì„
        user_input = st.text_input(f"ğŸ’¬ {main_menu}ì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.")

        if user_input:
            with st.status(f"ğŸš€ {selected_model} ì—”ì§„ ë¶„ì„ ì¤‘...", expanded=True) as status:
                # [ë°ì´í„° ìµœì í™”] 4.6MB ì „ì²´ëŠ” ë¬´ë¦¬ì´ë¯€ë¡œ, ê²€ìƒ‰ íš¨ìœ¨ì„ ìœ„í•´ ìµœì‹  400ì¤„ë¡œ ì œí•œ
                # ë§Œì•½ ì „ì²´ ë°ì´í„°ë¥¼ ë‹¤ ë³´ê³  ì‹¶ë‹¤ë©´ ìœ ë£Œ ë²„ì „ì´ë‚˜ ì„ë² ë”©(Vector DB) ê¸°ìˆ ì´ í•„ìš”í•´ìš”!
                refined_df = df.tail(400) 
                context_data = refined_df.to_csv(index=False)
                
                prompt = f"ì•„ë˜ [ë°ì´í„°]ë¥¼ ë³´ê³  ì§ˆë¬¸ì— ë‹µí•´ì¤˜.\n\n[ë°ì´í„°]\n{context_data}\n\n[ì§ˆë¬¸]\n{user_input}"
                
                answer = ask_ai(prompt, selected_model)
                status.update(label="âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", state="complete", expanded=False)
                st.info(answer)
    else:
        st.error("âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
except Exception as e:
    st.error(f"ğŸš¨ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
